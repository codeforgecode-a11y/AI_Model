# Multi-Dataset Training Requirements

# Core ML Libraries
torch>=2.0.0
transformers>=4.30.0
datasets>=2.12.0
accelerate>=0.20.0

# Data Processing
numpy>=1.21.0
pandas>=1.5.0
scikit-learn>=1.3.0

# Configuration and Utilities
pyyaml>=6.0
tqdm>=4.65.0
wandb>=0.15.0  # Optional: for experiment tracking

# Development and Testing
pytest>=7.0.0
black>=23.0.0
flake8>=6.0.0

# Optional: For advanced features
deepspeed>=0.9.0  # For distributed training
bitsandbytes>=0.39.0  # For 8-bit training
peft>=0.4.0  # For parameter-efficient fine-tuning (LoRA, etc.)

# System utilities
psutil>=5.9.0
GPUtil>=1.4.0